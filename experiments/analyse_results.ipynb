{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"deeplenv","language":"python","name":"deeplenv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"analyse_results.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"B84FZU9Gq_9r"},"source":["## Kết nối với Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0l6gxz61q1sR","executionInfo":{"status":"ok","timestamp":1619769275144,"user_tz":420,"elapsed":21574,"user":{"displayName":"Nguyễn Ích Thanh Tú","photoUrl":"","userId":"09234871255042424318"}},"outputId":"92c755e7-35a6-4dcf-df89-2560f39a87bd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HbTjOAkSqy6-","executionInfo":{"status":"ok","timestamp":1619769277615,"user_tz":420,"elapsed":2457,"user":{"displayName":"Nguyễn Ích Thanh Tú","photoUrl":"","userId":"09234871255042424318"}},"outputId":"77a74152-92e0-4f61-9048-bf584af0fa79"},"source":["%cd \"/content/drive/MyDrive/Car Recognition/Code\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Car Recognition/Code\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TxzbRb9UrSvK"},"source":["## Tạo tập dữ liệu Train & Test"]},{"cell_type":"code","metadata":{"id":"WIFIVa2hrSPU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619769335529,"user_tz":420,"elapsed":60358,"user":{"displayName":"Nguyễn Ích Thanh Tú","photoUrl":"","userId":"09234871255042424318"}},"outputId":"78501062-acd0-401c-ca89-69a275444ec9"},"source":["!mkdir \"/content/sample_data/car_datasets\"\n","print('Starting create train set')\n","!unzip \"/content/drive/MyDrive/Car Recognition/Code/Datasets/train.zip\" -d \"/content/sample_data/car_datasets\" > /dev/null 2>&1\n","print('Starting create test set')\n","!unzip \"/content/drive/MyDrive/Car Recognition/Code/Datasets/test.zip\" -d \"/content/sample_data/car_datasets\" > /dev/null 2>&1\n","print('Done!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Starting create train set\n","Starting create test set\n","Done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UXANyNdO6IWk"},"source":["%matplotlib inline\n","import os\n","import sys\n","import json\n","import random\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import collections\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","from IPython.display import Markdown, display\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import model_from_json\n","from tensorflow.keras.utils import plot_model\n","from sklearn.metrics import confusion_matrix\n","\n","from create_datagenerators import create_data_generators\n","from data_preprocessing import resize_white, resize_black\n","\n","def printmd(string):\n","    display(Markdown(string))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yykXerKSxzA0","executionInfo":{"status":"ok","timestamp":1619769379869,"user_tz":420,"elapsed":886,"user":{"displayName":"Nguyễn Ích Thanh Tú","photoUrl":"","userId":"09234871255042424318"}},"outputId":"e3da384e-2df9-479b-c1af-b93ddc98f405"},"source":["print(os.getcwd())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Car Recognition/Code\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SoEksNMP6IW9"},"source":["# default\n","SAVE_RESULRS_DIR = 'Saved_weights/'\n","RESULTS_FOLDER = SAVE_RESULRS_DIR + '/20190701_1148'\n","TRAIN_DIR = '/content/sample_data/car_datasets/train'\n","TEST_DIR = '/content/sample_data/car_datasets/test'\n","\n","resize = False\n","\n","HYPERPARAMS_FILE =  RESULTS_FOLDER+ '/hyperparams.json'\n","\n","with open(HYPERPARAMS_FILE, \"r\") as read_file:\n","    data = json.load(read_file)\n","\n","HYPERPARAMS = data['hyperparameters'][0]\n","BATCHSIZE = HYPERPARAMS['BATCHSIZE']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXoa4ZWI6IXE"},"source":["def load_image(img_path, input_shape, resize = False):\n","    if resize:\n","        img, pth = resize_black(input_shape[1], img_path, print_oldsize=False)\n","    else:\n","        img = image.load_img(img_path, target_size=input_shape)\n","    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n","    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n","    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n","    return img_tensor\n","\n","\n","        \n","def generate_data_generators(input_shape):\n","    generator_train, generator_test = create_data_generators(input_shape, BATCHSIZE, \n","                                                                TRAIN_DIR, TEST_DIR, \n","                                                                save_augumented=None, \n","                                                                plot_imgs = False)\n","    return generator_train, generator_test\n","        \n","        \n","def load_model(results_folder):\n","    # load json and create model\n","    json_file = open(results_folder + '/model.json', 'r')\n","    loaded_model_json = json_file.read()\n","    json_file.close()\n","    loaded_model = model_from_json(loaded_model_json)\n","    # load weights into new model\n","    loaded_model.load_weights(results_folder + \"/weights.best.hdf5\")\n","    input_shape = loaded_model.layers[0].output_shape[1:3]\n","    print(\"Loaded model from disk\")\n","    return loaded_model, input_shape\n","\n","\n","\n","def print_confusion_matrix(cls_pred, cls_test, class_names, cmap=plt.cm.Blues):\n","    '''Helper-function for printing confusion matrix'''\n","    # cls_pred is an array of the predicted class-number for\n","    # all images in the test-set.\n","    # Get the confusion matrix using sklearn.\n","    cm = confusion_matrix(y_true=cls_test,  # True class for test-set.\n","                          y_pred=cls_pred)  # Predicted class.\n","    print(\"Confusion matrix:\")\n","    # Print the confusion matrix as text.\n","    #print(cm)\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    # Print the class-names for easy reference.\n","    for i, class_name in enumerate(class_names):\n","        print(\"({0}) {1}\".format(i, class_name))\n","               \n","    \n","        \n","def decode_predictions(preds, class_names, top=5):\n","    results = []\n","    for pred in preds:\n","        top_indices = pred.argsort()[-top:][::-1]\n","        result = [(class_names[i], pred[i]) for i in top_indices]\n","        result.sort(key=lambda x: x[1], reverse=True)\n","        results.append(result)\n","    return results\n","\n","def predict(img_path, model, input_shape, class_names, correct_class, resize=False, show_imgs=True, top=5):\n","    img_array = load_image(img_path, input_shape, resize = resize)\n","    preds = model.predict(img_array)\n","    predictions = decode_predictions(preds, class_names, top=top)\n","    top1_pred = predictions[0][0]\n","    #print(predictions)\n","    #print(correct_class)\n","    if show_imgs:\n","        img_org = image.load_img(img_path)\n","        fig, axs = plt.subplots(1,2)\n","        axs[0].set_title(correct_class)\n","        axs[0].imshow(img_org)\n","        axs[1].set_title(str(top1_pred))\n","        axs[1].imshow(img_array[0])\n","        plt.show()\n","    return predictions\n","        \n","\n","def show_model_performance(loaded_model, generator_train, generator_test):\n","    steps_test = generator_test.n / BATCHSIZE\n","    steps_train = generator_test.n / BATCHSIZE\n","    cls_train = generator_train.classes\n","    cls_test = generator_test.classes\n","    class_names = list(generator_train.class_indices.keys())\n","    # Predict the classes for all images in the test-set\n","    y_pred = loaded_model.predict_generator(generator_test,\n","                                         steps=steps_test)\n","\n","    # Convert the predicted classes from arrays to integers.\n","    cls_pred = np.argmax(y_pred,axis=1)\n","\n","    # Plot examples of mis-classified images.\n","    # plot_example_errors(cls_pred)\n","    \n","    # Print the confusion matrix.\n","    print_confusion_matrix(cls_pred, cls_test, class_names)\n","    #result = loaded_model.evaluate_generator(generator_test, steps=steps_test)\n","    #result_train = loaded_model.evaluate_generator(generator_train, steps=steps_train)\n","    #print(\"Train-set classification accuracy: {0:.2%}\".format(result_train[1]))\n","    #print(\"Test-set classification accuracy: {0:.2%}\".format(result[1]))\n","        \n","def return_class_names_list(results_folder):\n","    class_names = []\n","    # open file and read the content in a list\n","    with open(results_folder+'/class_names.txt', 'r') as filehandle:  \n","        for line in filehandle:\n","            current_line = line[:-1]\n","            class_names.append(current_line)\n","    return class_names\n","        \n","def perform_pred(loaded_model, resize=False, car_class=None, img_pth=None, show_imgs=True):\n","    test_dir = TEST_DIR_TST\n","    results_folder = RESULTS_FOLDER\n","    \n","    if os.path.exists(results_folder+'/class_names.txt'):\n","        class_names = return_class_names_list(results_folder)\n","\n","    else:\n","        generator_train, generator_test = generate_data_generators(results_folder, input_shape)\n","        class_names = list(generator_train.class_indices.keys())\n","        print(class_names)\n","        with open(results_folder+'/class_names.txt', 'w') as filehandle:  \n","            for listitem in class_names:\n","                filehandle.write('%s\\n' % listitem)\n","                \n","    if car_class is None:\n","        car_class = random.choice(class_names)\n","    \n","    if img_pth is None: \n","        # randomly select an image from defined class     \n","        test_dir_full = test_dir + '/' + car_class\n","        test_img = test_dir_full + '/' + random.choice(os.listdir(test_dir_full))\n","    else:\n","        test_img = img_pth\n","        \n","    \n","    input_shape = loaded_model.layers[0].output_shape[1:3]\n","    \n","          \n","    predictions = predict(test_img, loaded_model, input_shape, class_names, car_class, resize=resize, show_imgs=show_imgs)\n","    print(predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dsmBVfmV6IXS","colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"status":"error","timestamp":1619769469335,"user_tz":420,"elapsed":3771,"user":{"displayName":"Nguyễn Ích Thanh Tú","photoUrl":"","userId":"09234871255042424318"}},"outputId":"eb95bdee-43c2-4d87-cc78-e98bc1cac694"},"source":["loaded_model, input_shape=load_model(RESULTS_FOLDER)\n","generator_train, generator_test = generate_data_generators(input_shape)\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-315e799e9031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgenerator_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-b399f828e1db>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(results_folder)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# load weights into new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/weights.best.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded model from disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2225\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2226\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2227\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2228\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2229\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'Saved_weights//20190701_1148/weights.best.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"]}]},{"cell_type":"code","metadata":{"id":"aX5MOE1R6IXU"},"source":["def take_make_from_classname(class_name):\n","    return class_name.split(' ', 1)[0]\n","\n","\n","def take_cartype_from_classname(class_name):\n","    elements = class_name.split()\n","    if class_name == 'Infiniti G Coupe IPL 2012':\n","        return elements[len(elements)-3]\n","    return elements[len(elements)-2]\n","\n","\n","\n","def return_most_common_brands(class_names):\n","    brands_in_dataset = []\n","    brands_in_dataset_common = []\n","    cnt = Counter()\n","    for class_name in class_names:\n","        brands_in_dataset.append(take_make_from_classname(class_name))\n","    brands_in_dataset_common = Counter(brands_in_dataset).most_common(30)\n","    brands_in_dataset_common = [element[0] for element in brands_in_dataset_common]\n","    return brands_in_dataset_common\n","\n","def return_car_types(class_names):\n","    car_types_in_dataset = []\n","    for class_name in class_names:\n","        car_types_in_dataset.append(take_cartype_from_classname(class_name))\n","    car_types_in_dataset_common = Counter(car_types_in_dataset).most_common(9)\n","    car_types_in_dataset_common = [element[0] for element in car_types_in_dataset_common]\n","    return car_types_in_dataset_common\n","\n","def is_popular_brand(class_name, popular_brands):\n","    return take_make_from_classname(class_name) in popular_brands\n","       \n","\n","def is_popular_type(class_name, popular_types):\n","    return take_cartype_from_classname(class_name) in popular_types\n","\n","#take_cartype_from_classname('Infiniti G Coupe IPL 2012')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T5X6TaO66IXU"},"source":["def plot_horizontal_bar(df, title='', fontsize=5, savepath='', many_data=True):\n","    if many_data:\n","        ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85, figsize=(10,25))\n","    else:\n","        ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85)\n","    ax.spines['right'].set_visible(False)\n","    ax.spines['top'].set_visible(False)\n","    ax.spines['left'].set_visible(False)\n","    ax.spines['bottom'].set_visible(False)\n","    plt.ylabel('Odpowiedź sieci', fontsize=12, weight='bold')\n","    plt.xlabel('Wystąpienia', fontsize=12, weight='bold')\n","    plt.title(title, fontsize=14, weight='bold')\n","    if savepath != '':\n","        fig_name = title + '.png'\n","        fig_path = savepath + '/' + fig_name\n","        plt.savefig(fig_path)\n","    plt.show()\n","\n","def plot_accuracy_for_all_classes(class_and_acc, title='', fontsize=5, savepath='', many_data=False):\n","    labels = list(class_and_acc.keys())\n","    values = list(class_and_acc.values())\n","    indexes = np.arange(len(labels))\n","    df = pd.DataFrame({'x' : labels , 'y' : values})\n","    df = df.sort_values('y',ascending = True)\n","    #df = df2[0:15]\n","    df = pd.DataFrame(list(zip(df['y'], df['x']))).set_index(1)\n","    # ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85, figsize=(10,45))\n","    if many_data:\n","        ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85, figsize=(10,25))\n","    else:\n","        ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85)\n","    ax.spines['right'].set_visible(False)\n","    ax.spines['top'].set_visible(False)\n","    ax.spines['left'].set_visible(False)\n","    ax.spines['bottom'].set_visible(False)\n","    plt.ylabel('Klasy', fontsize=12, weight='bold')\n","    plt.xlabel('Dokładność', fontsize=12, weight='bold')\n","    plt.title(title, fontsize=14, weight='bold')\n","    if savepath != '':\n","        fig_name = title + '.png'\n","        fig_path = savepath + '/' + fig_name\n","        plt.savefig(fig_path)\n","    plt.show()\n","\n","\n","\n","def mostcommon_predictions(list_of_preds, title='', fontsize=5, savepath='', many_data=True):\n","    cnt = Counter()\n","    for pred in list_of_preds:\n","        cnt[pred] += 1\n","    labels = list(cnt.keys())\n","    values = list(cnt.values())\n","    indexes = np.arange(len(labels))\n","    df = pd.DataFrame({'x' : labels , 'y' : values})\n","    df = df.sort_values('y',ascending = True)\n","    df = pd.DataFrame(list(zip(df['y'], df['x']))).set_index(1)\n","    if many_data:\n","        ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85, figsize=(10,25), fontsize = 16)\n","    else:\n","        ax = df.plot.barh(color='#86bf91', zorder=2, width=0.85, fontsize = 16)\n","    ax.spines['right'].set_visible(False)\n","    ax.spines['top'].set_visible(False)\n","    ax.spines['left'].set_visible(False)\n","    ax.spines['bottom'].set_visible(False)\n","    plt.ylabel('Odpowiedź sieci', fontsize=16, weight='bold')\n","    plt.xlabel('Wystąpienia', fontsize=16, weight='bold')\n","    plt.title(title, fontsize=14, weight='bold')\n","    if savepath != '':\n","        fig_name = title + '.png'\n","        fig_path = savepath + '/' + fig_name\n","        plt.savefig(fig_path)\n","    plt.show()\n","    return cnt\n","\n","\n","def plot_prediction_analysis_all(metrics):\n","    full_correct = metrics[0]\n","    correct_only_brand_or_type = metrics[2]\n","    full_incorrect = metrics[3]\n","    # Data to plot\n","    labels = 'Niepoprawne wskazania', 'Poprawne wskazania', 'Niepoprawne wskazania - ale zgadza się marka lub typ'\n","    sizes = [full_incorrect, full_correct, correct_only_brand_or_type]\n","    colors = ['yellowgreen', 'lightcoral', 'lightskyblue']\n","    explode = (0, 0.1, 0)  # explode 1st slice\n","    # Plot\n","    patches = plt.pie(sizes, explode=explode, colors=colors,\n","            autopct='%1.1f%%', shadow=True, startangle=160)\n","    plt.legend(patches[0], labels, loc=\"best\")\n","    plt.tight_layout()\n","    plt.axis('equal')\n","    plt.show()\n","    \n","def plot_prediction_analysis_brand(metrics):\n","    correct_brand = metrics[0] + metrics[1] # correct brand, doesn't matter if model\n","    incorrect_brand = (sum(metrics) - metrics[1]) - correct_brand\n","    # Data to plot\n","    labels = 'Prawidłowa marka', 'Nieprawidłowa marka'\n","    sizes = [correct_brand, incorrect_brand]\n","    colors = ['gold', 'lightskyblue']\n","    explode = (0.1, 0)  # explode 1st slice\n","    # Plot\n","    patches = plt.pie(sizes, explode=explode, colors=colors,\n","            autopct='%1.1f%%', shadow=True, startangle=160)\n","    plt.legend(patches[0], labels, loc=\"best\")\n","    plt.tight_layout()\n","    plt.axis('equal')\n","    plt.show()\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2JQsPOw6IXW"},"source":["#(img_path, model, input_shape, class_names, input_shape, class_names, correct_class, show_imgs=True, top=5):\n","class_names = return_class_names_list(RESULTS_FOLDER)\n","common_brands = return_most_common_brands(class_names)\n","common_types = return_car_types(class_names)\n","#resize = False\n","# print(common_brands)\n","# print(common_types)\n","\n","\n","def predict_on_class(model, input_shape, class_names, \n","                     common_brands, common_types, folder_path, resize=False, threshold=0.9999, \n","                     show_plots=True, print_analysis=True, savepath=''):\n","    \n","    class_name = os.path.basename(folder_path)\n","#     print('\\n\\n')\n","#     printmd('**'+class_name+'**')\n","    class_name_brand = take_make_from_classname(class_name)\n","    class_name_cartype = take_cartype_from_classname(class_name)\n","#     print(\"Brand:\", class_name_brand)\n","#     print(\"Type:\", class_name_cartype)\n","#     print('\\n')\n","    # verify popularity ===> boolean popular_cartype_or_brand = False\n","    n_correct_brand = None\n","    n_correct_brand_or_type = None # correct brand, but not necesserely model (fiat punto instead of fiat bravo)\n","    n_correct_type = None\n","    n_totally_incorrect = None\n","    \n","    \n","    if is_popular_brand(class_name, common_brands):\n","        n_correct_brand = 0\n","        n_correct_brand_or_type = 0\n","        n_totally_incorrect = 0\n","    else:\n","        print (\"The brand of car is not a popular brand. Statistics concerning brand won't be provided.\")\n","    if is_popular_type(class_name, common_types):\n","        n_correct_brand_or_type = 0\n","        n_totally_incorrect = 0\n","    else:\n","        print (\"The type of car is not a popular type. Statistics concerning type won't be provided.\")\n","\n","    \n","    main_return_dict = {}\n","    n_correct_make_and_model = 0 # correctly predicted (the higher value the better)\n","    n_corrects_high_confidence = 0 # correctly predicted with high confidence (>= threshold) (higher = better)\n","    n_incorrect_high_confidence = 0 # predicted incorrectly but with hight confidence (lowet = better)\n","    n_all_samples = 0 # all test/valid samples\n","    # all vars below concerns only the first prediction\n","\n","    #n_correct_brand = 0 # all correctly predicted brand: bmw, fiat, volvo etc \n","    #n_correct_type = 0 # wagon, hatchback, sedan etc (correct type but not necesserely make&model) (higher = better)\n","    incorrect_predictions_high_confidence = [] # concerns only first prediction (top1)\n","    incorrect_predictions = [] # concerns only first prediction (top1)\n","    all_top1_predictions = []\n","    top5accuracy = 0\n","    \n","    # list for further analysis\n","    top5_predictions = [] # all top 5 pred for all samples without their confidences into list\n","    top5_predictions_high = [] # top 5 pred for all samples into list only with conf higher than 0.3\n","\n","    for img in os.scandir(folder_path):\n","        n_all_samples+=1\n","        predictions = predict(os.path.abspath(img), model, input_shape, class_names, class_name, resize=resize, top=1, show_imgs=False)\n","        all_top1_predictions.append(predictions[0][0][0])\n","        if (predictions[0][0][0] == class_name):\n","            n_correct_make_and_model+=1\n","            if (float(predictions[0][0][1]) >= threshold):\n","                n_corrects_high_confidence+=1\n","        else:\n","            incorrect_predictions.append(predictions[0][0][0])\n","            if (float(predictions[0][0][1]) >= threshold):\n","                n_incorrect_high_confidence+=1\n","            if n_correct_brand is not None:\n","                if take_make_from_classname(predictions[0][0][0]) == class_name_brand:\n","                    n_correct_brand+=1\n","                    n_correct_brand_or_type+=1\n","                    #print(predictions[0][0][0])\n","                else:\n","                    if (n_correct_brand_or_type is not None) and (\n","                                                                take_cartype_from_classname(\n","                                                                predictions[0][0][0]) == class_name_cartype):\n","                        #print(predictions[0][0][0])\n","                        n_correct_brand_or_type+=1\n","            else:\n","                if (n_correct_brand_or_type is not None) and (\n","                                                                take_cartype_from_classname(\n","                                                                predictions[0][0][0]) == class_name_cartype):\n","                    #print(predictions[0][0][0])\n","                    n_correct_brand_or_type+=1\n","                        \n","        if n_correct_brand_or_type is not None:\n","            n_totally_incorrect = len(incorrect_predictions) - n_correct_brand_or_type\n","        else:\n","            n_correct_brand_or_type = len(incorrect_predictions)\n","            \n","\n","    accuracy = n_correct_make_and_model/n_all_samples*100\n","    correctly_pred_high_conf_perc = n_corrects_high_confidence/n_all_samples*100\n","    incorrectly_pred_hih_conf_perc = n_incorrect_high_confidence/n_all_samples*100\n","    brand_type_analysis = [n_correct_make_and_model, \n","                           n_correct_brand, n_correct_brand_or_type, n_totally_incorrect]\n","    \n","    #print(brand_type_analysis)\n","    if print_analysis:\n","        print(\"All samples: {}. Correctly predicted: {}. Accuracy: {}%.\".format(n_all_samples,\n","                    n_correct_make_and_model,accuracy))\n","        print(\"Correctly predicted with high confidence: {} => {}% of all.\".\n","              format(n_corrects_high_confidence,correctly_pred_high_conf_perc))\n","        print(\"Incorrectly predicted with high confidence: {} => {}% of all. \".\n","              format(n_incorrect_high_confidence,incorrectly_pred_hih_conf_perc))\n","        #print(brand_type_analysis)\n","    \n","    if show_plots:\n","        #mostcommon_predictions(top5_predictions, class_name+': '+'Most common top5 predictions',\n","                               #savepath=savepath)\n","\n","        if n_correct_brand is not None:\n","            plot_prediction_analysis_all(brand_type_analysis)\n","            plot_prediction_analysis_brand(brand_type_analysis)\n","        else:\n","            if n_correct_brand_or_type is not None:\n","                plot_prediction_analysis_all(brand_type_analysis)\n","        \n","        mostcommon_predictions(all_top1_predictions, \n","                                    class_name, many_data=False,\n","                                    savepath=savepath)\n","      \n","    return accuracy, correctly_pred_high_conf_perc, incorrectly_pred_hih_conf_perc, brand_type_analysis\n","\n","\n","#                 TEST_DIR_TST + '/Dodge Caliber Wagon 2012')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qhYOYAR6IXZ"},"source":["predict_on_class(loaded_model, input_shape, \n","                 class_names, common_brands, common_types, \n","                 TEST_DIR + '/BMW ActiveHybrid 5 Sedan 2012', resize=resize, show_plots=True, print_analysis=False)\n","\n","# predict_on_class(loaded_model, input_shape, \n","#                  class_names, common_brands, common_types, \n","#  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-hGlk8do6IXa"},"source":["class_names = return_class_names_list(RESULTS_FOLDER)\n","common_brands = return_most_common_brands(class_names)\n","common_types = return_car_types(class_names)\n","\n","def create_folder_with_analysis(results_folder):\n","    # name of dir\n","    ANALYSIS_PATH = \"../saved_models/\" + results_folder + \"/resuls_analysis\"\n","    access_rights = 0o755\n","    try:  \n","        os.makedirs(ANALYSIS_PATH, access_rights)\n","    except OSError:  \n","        print (\"Creation of the directory %s failed\" % ANALYSIS_PATH)\n","    else:  \n","        print (\"Successfully created the directory %s\" % ANALYSIS_PATH)\n","    return ANALYSIS_PATH\n","\n","def analyse_all_classes(loaded_model, results_folder, test_directory, resize=False):\n","    # create target folder\n","    ANALYSIS_PATH = create_folder_with_analysis(results_folder)\n","    general_acc_dict = {}\n","    incorrect_high_conf = {}\n","    brand_type_analysis_counter = [0,0,0,0]\n","    brand_analysis_counter = [0,0,0,0]\n","    if os.path.exists(ANALYSIS_PATH):\n","        for subfolder in os.scandir(test_directory):\n","            class_name_path = os.path.abspath(subfolder)\n","            results_for_class=predict_on_class(loaded_model, input_shape, class_names, \n","                                                    common_brands, common_types, \n","                                                    class_name_path, resize=resize, threshold=0.9999, \n","                                                    print_analysis=False, show_plots=False, \n","                                                    savepath=ANALYSIS_PATH)\n","            brand_type_an_oneclass = results_for_class[3]\n","\n","            if brand_type_an_oneclass[1] is not None:\n","                for n in range(0,4):\n","                    brand_analysis_counter[n] = brand_analysis_counter[n] + brand_type_an_oneclass[n]\n","                    brand_type_analysis_counter[n] = brand_type_analysis_counter[n] + brand_type_an_oneclass[n]\n","            elif brand_type_an_oneclass[1] is None and brand_type_an_oneclass[2] is not None:\n","                for n in range(0,4):\n","                    if n != 1:\n","                        brand_type_analysis_counter[n] = brand_type_analysis_counter[n] + brand_type_an_oneclass[n]\n","            else:\n","                continue\n","            general_acc_dict[subfolder.name] = results_for_class[0]\n","            incorrect_high_conf[subfolder.name] = results_for_class[2]\n","#     # plot overall analysis of general accuracy\n","#     plot_accuracy_for_all_classes(general_acc_dict, title='Dokładność odpowiedzi sieci dla poszczególnych klas', \n","#                                   fontsize=5, savepath='', many_data=False)\n","    # plot overall analysis of general accuracy for 15 best recognizable cars\n","    sorted_general_acc_dict = sorted(general_acc_dict.items(), key=lambda kv: kv[1], reverse=True)\n","    sorted_general_acc_Dict = collections.OrderedDict(sorted_general_acc_dict)\n","#     print(sorted_general_acc_Dict)\n","    sorted_general_acc_Dict_sliced = dict(itertools.islice(sorted_general_acc_Dict.items(), 15))\n","    plot_accuracy_for_all_classes(sorted_general_acc_Dict_sliced, title='Dokładność odpowiedzi sieci dla poszczególnych klas', \n","                                  fontsize=5, savepath='', many_data=False)\n","    # plot overall analysis of incorrectly predicted\n","#     plot_accuracy_for_all_classes(incorrect_high_conf, \n","#                                   title='Incorrect predictions with confidence', \n","#                                   fontsize=5, savepath='', many_data=True)\n","    # plot overall analysis of correctly/incorrectly predicted due to brand\n","#     print(brand_analysis_counter)\n","    plot_prediction_analysis_brand(brand_analysis_counter)\n","    # plot overall analysis of correctly pred/correctly brand/cartype\n","    plot_prediction_analysis_all(brand_type_analysis_counter)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Li--Qmc36IXb"},"source":["#TEST_DIR_TST = '/media/kamila/System/Users/Kama/Documents/DATASETS/carsStanford_s/test'\n","analyse_all_classes(loaded_model, RESULTS_FOLDER,TEST_DIR_TST, resize=resize)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjeEnj3j6IXc"},"source":[""],"execution_count":null,"outputs":[]}]}